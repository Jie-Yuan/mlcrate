from .time import Timer

def train_kfold(model, x_train, y_train, x_test=None, folds=5, metrics=None, predict_type='predict_proba', stratify=None, random_state=1337, skip_checks=False):
    """Trains a set of sklearn models with chosen parameters on a KFold split dataset, returning full out-of-fold
    training set predictions (useful for stacking) as well as test set predictions and the models themselves.
    Test set predictions are generated by averaging predictions from all the individual fold models - this means
    1 model fewer has to be trained and from my experience performs better than retraining a single model on the full set.

    Optionally, the split can be stratified along a passed array.

    Keyword arguments:
    model -- An instance of an (untrained) sklearn-style model with fit & predict methods
    x_train -- The training set features
    y_train -- The training set labels
    x_test (optional) -- The test set features
    metrics (optional) -- A metric or list of metric functions to use for evaluating the models
    predict_type (default: 'predict_proba') -- Must be one of ['predict', 'predict_proba'], which prediction method to call on the trained sklearn models
    folds (default: 5) -- The number of folds to perform
    stratify (optional) -- An array to stratify the splits along
    random_state (default: 1337) -- Random seed for splitting folds
    skip_checks -- By default, this function tries to reorder the test set columns to match the order of the training set columns. Set this to disable this behaviour.

    Returns:
    models -- a list of trained xgboost.Booster objects
    p_train -- Out-of-fold training set predictions (shaped like y_train)
    p_test -- Mean of test set predictions from the models. Returns None if 'x_test' was not provided.
    """
    from sklearn.model_selection import KFold, StratifiedKFold  # Optional dependencies
    from sklearn.base import clone
    import numpy as np

    assert predict_type in ['predict', 'predict_proba'], "predict_type must be set to one of ['predict', 'predict_proba']"

    # If it's a dataframe, we can take column names, otherwise just use column indices.
    if hasattr(x_train, 'columns'):
        columns = x_train.columns.values
        columns_exists = True
    else:
        columns = np.arange(x_train.shape[1])
        columns_exists = False

    x_train = np.asarray(x_train)
    y_train = np.array(y_train)

    if not hasattr(metrics, '__iter__'):
        metrics = [metrics]

    if x_test is not None:
        if columns_exists and not skip_checks:
            try:
                x_test = x_test[columns]
            except Exception as e:
                print('[mlcrate] Could not coerce x_test columns to match x_train columns. Set skip_checks=True to run anyway.')
                raise e

        x_test = np.asarray(x_test)

    if not skip_checks and x_test is not None:
        assert x_train.shape[1] == x_test.shape[1], "x_train and x_test have different numbers of features."

    print('[mlcrate] Training {} {}{} models on training set {} {}'.format(folds, 'stratified ' if stratify is not None else '', type(model),
            x_train.shape, 'with test set {}'.format(x_test.shape) if x_test is not None else 'without a test set'))

    # Init a timer to get fold durations
    t = Timer()

    if stratify is not None:
        kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=random_state)
        splits = kf.split(x_train, stratify)
    else:
        kf = KFold(n_splits=folds, shuffle=True, random_state=4242)
        splits = kf.split(x_train)

    p_train = np.zeros_like(y_train, dtype=np.float32)
    ps_test = []
    models = []

    fold_i = 0
    for train_kf, valid_kf in splits:
        print('[mlcrate] Running fold {}, {} train samples, {} validation samples'.format(fold_i, len(train_kf), len(valid_kf)))
        x_tr, y_tr = x_train[train_kf], y_train[train_kf]
        x_va, y_va = x_train[valid_kf], y_train[valid_kf]

        # Start a timer for the fold
        t.add('fold{}'.format(fold_i))

        mdl = clone(model)
        mdl.fit(x_tr, y_tr)

        if predict_type == 'predict':
            p_va = model.predict(x_va)
            if x_test:
                p_test = model.predict(x_test)
        else:
            p_va = model.predict_proba(x_va)
            if x_test:
                p_test = model.predict_proba(x_test)

        p_train[valid_kf] = p_va

        if metrics:
            valid_scores = [metric(y_va, p_va) for metric in metrics]
        else:
            valid_scores = 'Set metrics to see scores!'

        print('[mlcrate] Finished training fold {} - took {} - scores: {}'.format(fold_i, t.format_elapsed('fold{}'.format(fold_i)), valid_scores))

        if x_test:
            ps_test.append(p_test)
        models.append(mdl)

        fold_i += 1

    if metrics:
        scores = [metric(y_train, p_train) for metric in metrics]
    else:
        scores = 'Set metrics to see scores!'

    if x_test is not None:
        p_test = np.mean(ps_test, axis=0)
    else:
        p_test = None

    print('[mlcrate] Finished training {} models, took {} - CV scores: {}'.format(folds, t.format_elapsed(0)), scores)

    return models, p_train, p_test
